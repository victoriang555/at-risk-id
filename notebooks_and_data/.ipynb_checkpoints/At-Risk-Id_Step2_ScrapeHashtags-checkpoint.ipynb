{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/victoria/anaconda3/envs/ds/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# General system libraries\n",
    "import os\n",
    "import sys\n",
    "from IPython.display import Image, Markdown\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "# Dataframe libraries\n",
    "import pandas as pd\n",
    "from pandas import DataFrame, read_csv\n",
    "\n",
    "# Number manipulation\n",
    "import scipy.sparse\n",
    "from scipy.ndimage.filters import generic_filter\n",
    "import patsy\n",
    "import numpy as np\n",
    "\n",
    "# Plotting libaries\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "plt.style.use('ggplot')\n",
    "%matplotlib inline\n",
    "\n",
    "# Data type libaries\n",
    "from datetime import datetime as dt\n",
    "\n",
    "# File manipulation\n",
    "import pickle\n",
    "import pandas.io.sql as pd_sql\n",
    "from sqlalchemy import create_engine\n",
    "import psycopg2 as pg\n",
    "\n",
    "# NLP libraries\n",
    "import wikipedia as wiki\n",
    "from nltk import word_tokenize, sent_tokenize,FreqDist\n",
    "from nltk.corpus import stopwords\n",
    "import gensim as gn\n",
    "from gensim import corpora, models, similarities\n",
    "from collections import defaultdict\n",
    "from six import iteritems\n",
    "from sklearn.feature_extraction.stop_words import ENGLISH_STOP_WORDS\n",
    "from spacy.lang.en.stop_words import STOP_WORDS\n",
    "\n",
    "# Scraping libraries\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "import time\n",
    "from scraping_functions.tumblr_api import get_client\n",
    "\n",
    "# Stats libaries\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.cross_validation import cross_val_score, cross_val_predict\n",
    "from sklearn.preprocessing import StandardScaler, PolynomialFeatures\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.linear_model import Ridge, Lasso, RidgeCV, LinearRegression\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import mean_squared_error, mean_absolute_error\n",
    "from sklearn import svm, datasets\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "\n",
    "# Other libaries\n",
    "import geopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['webdriver.chrome.driver'] = 'chromedriver'\n",
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_related_hashtags(initial_hashtag):\n",
    "    driver.get('https://top-hashtags.com/hashtag/{}'.format(initial_hashtag))\n",
    "    all_hashtags = []\n",
    "    for idx in range(1,6):\n",
    "        hashtags = driver.find_element_by_id('clip-tags-{}'.format(idx)).text\n",
    "        all_hashtags.append(hashtags)\n",
    "    return all_hashtags                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
